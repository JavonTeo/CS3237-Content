{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import sklearn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at (SGT)</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>gas</th>\n",
       "      <th>dampness</th>\n",
       "      <th>bin depth</th>\n",
       "      <th>human count</th>\n",
       "      <th>satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7/10/2023 22:55</td>\n",
       "      <td>30.50</td>\n",
       "      <td>64.00</td>\n",
       "      <td>1796</td>\n",
       "      <td>4095</td>\n",
       "      <td>15.00</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7/10/2023 23:05</td>\n",
       "      <td>30.40</td>\n",
       "      <td>64.00</td>\n",
       "      <td>1796</td>\n",
       "      <td>4095</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7/10/2023 23:15</td>\n",
       "      <td>30.40</td>\n",
       "      <td>65.00</td>\n",
       "      <td>1793</td>\n",
       "      <td>4095</td>\n",
       "      <td>15.00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7/10/2023 23:25</td>\n",
       "      <td>30.40</td>\n",
       "      <td>65.00</td>\n",
       "      <td>1780</td>\n",
       "      <td>4095</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7/10/2023 23:35</td>\n",
       "      <td>30.40</td>\n",
       "      <td>65.00</td>\n",
       "      <td>1780</td>\n",
       "      <td>4095</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>NaN</td>\n",
       "      <td>31.67</td>\n",
       "      <td>64.52</td>\n",
       "      <td>1825</td>\n",
       "      <td>2182</td>\n",
       "      <td>7.70</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>NaN</td>\n",
       "      <td>32.97</td>\n",
       "      <td>63.48</td>\n",
       "      <td>1909</td>\n",
       "      <td>2337</td>\n",
       "      <td>11.23</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>NaN</td>\n",
       "      <td>31.29</td>\n",
       "      <td>68.36</td>\n",
       "      <td>1980</td>\n",
       "      <td>3339</td>\n",
       "      <td>13.07</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>NaN</td>\n",
       "      <td>28.39</td>\n",
       "      <td>57.56</td>\n",
       "      <td>1851</td>\n",
       "      <td>3011</td>\n",
       "      <td>11.64</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>NaN</td>\n",
       "      <td>31.54</td>\n",
       "      <td>57.69</td>\n",
       "      <td>1939</td>\n",
       "      <td>2670</td>\n",
       "      <td>12.52</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>706 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    created_at (SGT)   temp  humidity   gas  dampness  bin depth  human count  \\\n",
       "0    7/10/2023 22:55  30.50     64.00  1796      4095      15.00            2   \n",
       "1    7/10/2023 23:05  30.40     64.00  1796      4095      15.00            0   \n",
       "2    7/10/2023 23:15  30.40     65.00  1793      4095      15.00            1   \n",
       "3    7/10/2023 23:25  30.40     65.00  1780      4095      15.00            0   \n",
       "4    7/10/2023 23:35  30.40     65.00  1780      4095      15.00            0   \n",
       "..               ...    ...       ...   ...       ...        ...          ...   \n",
       "701              NaN  31.67     64.52  1825      2182       7.70            5   \n",
       "702              NaN  32.97     63.48  1909      2337      11.23           18   \n",
       "703              NaN  31.29     68.36  1980      3339      13.07           16   \n",
       "704              NaN  28.39     57.56  1851      3011      11.64            5   \n",
       "705              NaN  31.54     57.69  1939      2670      12.52           16   \n",
       "\n",
       "     satisfaction  \n",
       "0               4  \n",
       "1               4  \n",
       "2               4  \n",
       "3               5  \n",
       "4               4  \n",
       "..            ...  \n",
       "701             3  \n",
       "702             2  \n",
       "703             3  \n",
       "704             4  \n",
       "705             3  \n",
       "\n",
       "[706 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./consolidated_data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = data[[\"temp\", \"humidity\", \"gas\", \"dampness\", \"bin depth\", \"human count\"]]\n",
    "data_Y = data[\"satisfaction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data_X)\n",
    "X = scaler.transform(data_X)\n",
    "Y = data_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Naive Bayes classifer correctly classified 33.6879% of the training data irises.\n",
      "The Naive Bayes classifer correctly classified 30.9859% of the test data irises.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "pred_train = clf.predict(X_train)\n",
    "perf_train = np.mean(pred_train == Y_train)\n",
    "print(\"The Naive Bayes classifer correctly classified %3.4f%% of the training data irises.\" % (perf_train * 100.0))\n",
    "\n",
    "pred_test = clf.predict(X_test)\n",
    "perf_test = np.mean(pred_test == Y_test)\n",
    "print(\"The Naive Bayes classifer correctly classified %3.4f%% of the test data irises.\" % (perf_test * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Pipeline [StandardScaler, LinearSVC] correctly classified 21.2766% of the training data irises\n",
      "The Pipeline [StandardScaler, LinearSVC] correctly classified 19.0141% of the testing data irises\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "svc_pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                     ('linearSVC', LinearSVC(max_iter = 100000, loss = 'hinge', penalty = 'l2', dual = 'auto'))])\n",
    "svc_pipe.fit(X_train, Y_train)\n",
    "\n",
    "pred_train = svc_pipe.predict(X_train)\n",
    "perf_train = np.mean(pred_train == Y_train)\n",
    "print(\"The Pipeline [StandardScaler, LinearSVC] correctly classified %3.4f%% of the training data irises\" % (perf_train * 100.0))\n",
    "\n",
    "pred_test = svc_pipe.predict(X_test)\n",
    "perf_test = np.mean(pred_test == Y_test)\n",
    "print(\"The Pipeline [StandardScaler, LinearSVC] correctly classified %3.4f%% of the testing data irises\" % (perf_test * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javonteo/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Pipeline [StandardScaler, GridSearchCV(SVC)] correctly classified 64.1844% of the training data irises\n",
      "The Pipeline [StandardScaler, GridSearchCV(SVC)] correctly classified 35.9155% of the testing data irises\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "C_params = {'C':[1, 10]}\n",
    "kernel_params = {'kernel':('linear', 'poly', 'rbf', 'sigmoid')}\n",
    "decision_function_shape_params = {'decision_function_shape':('ovr', 'ovo')}\n",
    "\n",
    "SVC_pipeline = Pipeline([('scaler', StandardScaler()),\n",
    "                         ('svc', GridSearchCV(SVC(max_iter = 10000), [C_params, kernel_params, decision_function_shape_params])), ])\n",
    "SVC_pipeline.fit(X_train, Y_train)\n",
    "\n",
    "pred_train = SVC_pipeline.predict(X_train)\n",
    "perf_train = np.mean(pred_train == Y_train)\n",
    "print(\"The Pipeline [StandardScaler, GridSearchCV(SVC)] correctly classified %3.4f%% of the training data irises\" % (perf_train * 100.0))\n",
    "\n",
    "pred_test = SVC_pipeline.predict(X_test)\n",
    "perf_test = np.mean(pred_test == Y_test)\n",
    "print(\"The Pipeline [StandardScaler, GridSearchCV(SVC)] correctly classified %3.4f%% of the testing data irises\" % (perf_test * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Models is not complex enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelNN, self).__init__()\n",
    "        self.l1 = nn.Linear(6, 128)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.l2 = nn.Linear(128, 1024)\n",
    "        self.l3 = nn.Linear(1024, 64)\n",
    "        self.l4 = nn.Linear(64, 6) # 5 classes: from 1-5\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.l2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.l3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        output = self.l4(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "training_set = TensorDataset(torch.Tensor(X_train).to(device), torch.tensor(Y_train.values).to(device))\n",
    "test_set = TensorDataset(torch.Tensor(X_test).to(device), torch.tensor(Y_test.values).to(device))\n",
    "train_loader = DataLoader(training_set, batch_size = batch_size)\n",
    "test_loader = DataLoader(test_set, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [50/57], Loss: 1.7454\n",
      "Epoch [2/10], Step [50/57], Loss: 1.7225\n",
      "Epoch [3/10], Step [50/57], Loss: 1.7086\n",
      "Epoch [4/10], Step [50/57], Loss: 1.6841\n",
      "Epoch [5/10], Step [50/57], Loss: 1.6697\n",
      "Epoch [6/10], Step [50/57], Loss: 1.6710\n",
      "Epoch [7/10], Step [50/57], Loss: 1.6598\n",
      "Epoch [8/10], Step [50/57], Loss: 1.6486\n",
      "Epoch [9/10], Step [50/57], Loss: 1.6438\n",
      "Epoch [10/10], Step [50/57], Loss: 1.6296\n",
      "Training complete!\n",
      "Accuracy of the model on the 564 training data: 32.09219858156028 %\n"
     ]
    }
   ],
   "source": [
    "model = ModelNN()\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# data.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (data, labels) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 50 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"Training complete!\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for rows, labels in train_loader:\n",
    "        outputs = model(rows)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the model on the {len(X_train)} training data: {100 * correct / total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelNN(\n",
      "  (l1): Linear(in_features=6, out_features=128, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (l2): Linear(in_features=128, out_features=1024, bias=True)\n",
      "  (l3): Linear(in_features=1024, out_features=64, bias=True)\n",
      "  (l4): Linear(in_features=64, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provided model function fails when applied to the provided data set.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m explainer \u001b[38;5;241m=\u001b[39m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKernelExplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mshap_values(X_test)\n\u001b[1;32m      4\u001b[0m shap\u001b[38;5;241m.\u001b[39msummary_plot(shap_values, X_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/shap/explainers/_kernel.py:96\u001b[0m, in \u001b[0;36mKernelExplainer.__init__\u001b[0;34m(self, model, data, feature_names, link, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m convert_to_model(model, keep_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_index)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m convert_to_data(data, keep_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_index)\n\u001b[0;32m---> 96\u001b[0m model_null \u001b[38;5;241m=\u001b[39m \u001b[43mmatch_model_to_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# enforce our current input type limitations\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, DenseData) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, SparseData), \\\n\u001b[1;32m    100\u001b[0m        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShap explainer only supports the DenseData and SparseData input currently.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/shap/utils/_legacy.py:136\u001b[0m, in \u001b[0;36mmatch_model_to_data\u001b[0;34m(model, data)\u001b[0m\n\u001b[1;32m    134\u001b[0m         out_val \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mf(data\u001b[38;5;241m.\u001b[39mconvert_to_df())\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m         out_val \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvided model function fails when applied to the provided data set.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[9], line 11\u001b[0m, in \u001b[0;36mModelNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 11\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     13\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "explainer = shap.KernelExplainer(model, X_train)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
