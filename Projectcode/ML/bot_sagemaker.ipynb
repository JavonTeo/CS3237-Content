{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48bc4ec6-8f43-42f4-b825-9e1816adf9e4",
   "metadata": {},
   "source": [
    "Installation of Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "561f2a8e-809b-4d45-b89b-2246fe4c6bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c1bfc0b-05f7-4031-a9e4-999fedb64cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/6d/13/b5e8bacd980b2195f8a1741ce11cbb9146568607795d5e4ff510dcff1064/torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl.metadata\n",
      "  Using cached torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2022.7.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
      "  Obtaining dependency information for nvidia-cudnn-cu12==8.9.2.26 from https://files.pythonhosted.org/packages/ff/74/a2e2be7fb83aaedec84f391f082cf765dfb635e7caa9b49065f73e4835d8/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-nccl-cu12==2.18.1 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting triton==2.1.0 (from torch)\n",
      "  Obtaining dependency information for triton==2.1.0 from https://files.pythonhosted.org/packages/4d/22/91a8af421c8a8902dde76e6ef3db01b258af16c53d81e8c0d0dc13900a9e/triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Using cached triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Obtaining dependency information for nvidia-nvjitlink-cu12 from https://files.pythonhosted.org/packages/45/de/885b6d3e1fa07bf19124076b348d3cf30f68051f813cba99e103f53d2f75/nvidia_nvjitlink_cu12-12.3.52-py3-none-manylinux1_x86_64.whl.metadata\n",
      "  Using cached nvidia_nvjitlink_cu12-12.3.52-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eefa8c5-969f-409e-b17d-906ba402115d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting telebot\n",
      "  Using cached telebot-0.0.5-py3-none-any.whl (4.8 kB)\n",
      "Collecting pyTelegramBotAPI (from telebot)\n",
      "  Using cached pyTelegramBotAPI-4.14.0-py3-none-any.whl\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from telebot) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->telebot) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->telebot) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->telebot) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->telebot) (2023.7.22)\n",
      "Installing collected packages: pyTelegramBotAPI, telebot\n",
      "Successfully installed pyTelegramBotAPI-4.14.0 telebot-0.0.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install telebot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cb21e14-e3ec-4f55-b0e8-3dde7068eeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.2.1)\n",
      "Collecting pip\n",
      "  Obtaining dependency information for pip from https://files.pythonhosted.org/packages/47/6a/453160888fab7c6a432a6e25f8afe6256d0d9f2cbd25971021da6491d899/pip-23.3.1-py3-none-any.whl.metadata\n",
      "  Using cached pip-23.3.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Using cached pip-23.3.1-py3-none-any.whl (2.1 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.2.1\n",
      "    Uninstalling pip-23.2.1:\n",
      "      Successfully uninstalled pip-23.2.1\n",
      "Successfully installed pip-23.3.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting torch\n",
      "  Using cached torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2022.7.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-nccl-cu12==2.18.1 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting triton==2.1.0 (from torch)\n",
      "  Using cached triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.3.52-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Using cached torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Using cached triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.52 nvidia-nvtx-cu12-12.1.105 torch-2.1.0 triton-2.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c738879-f62c-4108-b9a4-ea2ca362b396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pickle-mixin\n",
      "  Using cached pickle_mixin-1.0.2-py3-none-any.whl\n",
      "Installing collected packages: pickle-mixin\n",
      "Successfully installed pickle-mixin-1.0.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pickle-mixin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83a295f-b757-4fe8-a8de-2c8577cbe682",
   "metadata": {},
   "source": [
    "Actual Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8623e34b-0897-4ac1-926d-d3723e03559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime \n",
    "\n",
    "import telebot\n",
    "from telebot import types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e62c2bc4-5678-4a7c-9044-b13e884e5fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:324: UserWarning: Trying to unpickle estimator StandardScaler from version 1.0 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "\n",
    "class ModelNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelNN, self).__init__()\n",
    "        self.l1 = nn.Linear(6, 128)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.l2 = nn.Linear(128, 64)\n",
    "        self.l3 = nn.Linear(64, 5) # 5 classes: from 1-5\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.l2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        output = self.l3(x)\n",
    "        return output\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size = 6, hidden_size = hidden_size, num_layers = num_layers, batch_first= True)\n",
    "        self.output = nn.Linear(hidden_size, 6)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Load LSTM\n",
    "lstm = torch.load('lstm.pth')\n",
    "lstm.eval()  # Put the model in evaluation model\n",
    "\n",
    "# Load Neural Network \n",
    "classifier = torch.load('classify_nn.pth')\n",
    "classifier.eval()  # Put the model in evaluation model \n",
    "\n",
    "# Load standard scaler \n",
    "with open('lstm_sc.pkl','rb') as f:\n",
    "    sc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f63be10a-4f75-488c-b3c3-958f4669b968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>gas</th>\n",
       "      <th>motion</th>\n",
       "      <th>dampness</th>\n",
       "      <th>trash</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>0:00</td>\n",
       "      <td>25.877322</td>\n",
       "      <td>76.955939</td>\n",
       "      <td>775.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4095.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>0:05</td>\n",
       "      <td>25.139135</td>\n",
       "      <td>76.425273</td>\n",
       "      <td>725.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4095.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>0:10</td>\n",
       "      <td>26.843238</td>\n",
       "      <td>77.102513</td>\n",
       "      <td>769.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4095.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>0:15</td>\n",
       "      <td>25.344632</td>\n",
       "      <td>76.212004</td>\n",
       "      <td>724.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4095.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>0:20</td>\n",
       "      <td>26.764051</td>\n",
       "      <td>76.274117</td>\n",
       "      <td>745.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4095.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12094</th>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>23:50</td>\n",
       "      <td>25.228414</td>\n",
       "      <td>78.670817</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2560.914603</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12095</th>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>23:55</td>\n",
       "      <td>26.209149</td>\n",
       "      <td>78.045677</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2527.698203</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12096</th>\n",
       "      <td>2023-11-13</td>\n",
       "      <td>22:40</td>\n",
       "      <td>30.700001</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1504.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4095.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12097</th>\n",
       "      <td>2023-11-13</td>\n",
       "      <td>22:40</td>\n",
       "      <td>30.700001</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1478.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4095.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12098</th>\n",
       "      <td>2023-11-13</td>\n",
       "      <td>22:40</td>\n",
       "      <td>30.700001</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1494.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4095.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12099 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              day   time  temperature   humidity     gas  motion     dampness  \\\n",
       "0      2023-11-01   0:00    25.877322  76.955939   775.0       0  4095.000000   \n",
       "1      2023-11-01   0:05    25.139135  76.425273   725.0       0  4095.000000   \n",
       "2      2023-11-01   0:10    26.843238  77.102513   769.0       0  4095.000000   \n",
       "3      2023-11-01   0:15    25.344632  76.212004   724.0       0  4095.000000   \n",
       "4      2023-11-01   0:20    26.764051  76.274117   745.0       0  4095.000000   \n",
       "...           ...    ...          ...        ...     ...     ...          ...   \n",
       "12094  2023-12-12  23:50    25.228414  78.670817  1123.0       0  2560.914603   \n",
       "12095  2023-12-12  23:55    26.209149  78.045677  1284.0       0  2527.698203   \n",
       "12096  2023-11-13  22:40    30.700001  60.000000  1504.0      10  4095.000000   \n",
       "12097  2023-11-13  22:40    30.700001  60.000000  1478.0      10  4095.000000   \n",
       "12098  2023-11-13  22:40    30.700001  60.000000  1494.0      10  4095.000000   \n",
       "\n",
       "       trash  rating  \n",
       "0       15.0    5.00  \n",
       "1       15.0    5.00  \n",
       "2       15.0    5.00  \n",
       "3       15.0    5.00  \n",
       "4       15.0    4.00  \n",
       "...      ...     ...  \n",
       "12094    3.0    4.00  \n",
       "12095    3.0    3.00  \n",
       "12096   15.0    4.95  \n",
       "12097   15.0    4.95  \n",
       "12098   15.0    4.95  \n",
       "\n",
       "[12099 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"s3://iotcore-to-s3-bucket/data/data.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36dac3e7-717a-4839-a90a-2ebe7e2dbbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>gas</th>\n",
       "      <th>motion</th>\n",
       "      <th>dampness</th>\n",
       "      <th>trash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12075</th>\n",
       "      <td>25.352686</td>\n",
       "      <td>81.812249</td>\n",
       "      <td>1303.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2539.400689</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12076</th>\n",
       "      <td>25.286756</td>\n",
       "      <td>80.563007</td>\n",
       "      <td>1396.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2569.288370</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12077</th>\n",
       "      <td>25.983841</td>\n",
       "      <td>80.523062</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2574.292953</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12078</th>\n",
       "      <td>25.813435</td>\n",
       "      <td>81.497120</td>\n",
       "      <td>1348.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2570.832162</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12079</th>\n",
       "      <td>26.150245</td>\n",
       "      <td>81.782440</td>\n",
       "      <td>1176.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2554.995460</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12080</th>\n",
       "      <td>25.309083</td>\n",
       "      <td>78.560073</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2551.334335</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12081</th>\n",
       "      <td>25.911777</td>\n",
       "      <td>79.555061</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2560.659132</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12082</th>\n",
       "      <td>26.179877</td>\n",
       "      <td>78.652718</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2570.963033</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12083</th>\n",
       "      <td>25.292050</td>\n",
       "      <td>79.030021</td>\n",
       "      <td>1221.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2544.486094</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12084</th>\n",
       "      <td>25.944225</td>\n",
       "      <td>79.344535</td>\n",
       "      <td>1122.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2583.068353</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12085</th>\n",
       "      <td>25.508473</td>\n",
       "      <td>78.970599</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2536.759795</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12086</th>\n",
       "      <td>26.104548</td>\n",
       "      <td>78.876024</td>\n",
       "      <td>1157.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2512.302062</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12087</th>\n",
       "      <td>26.137773</td>\n",
       "      <td>79.108537</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2502.450573</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12088</th>\n",
       "      <td>26.988470</td>\n",
       "      <td>78.219620</td>\n",
       "      <td>1268.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2539.282232</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12089</th>\n",
       "      <td>25.528272</td>\n",
       "      <td>78.287858</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2563.526508</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12090</th>\n",
       "      <td>25.813820</td>\n",
       "      <td>78.988355</td>\n",
       "      <td>1236.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2549.314699</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12091</th>\n",
       "      <td>26.284555</td>\n",
       "      <td>78.988115</td>\n",
       "      <td>1275.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2567.093076</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12092</th>\n",
       "      <td>26.898266</td>\n",
       "      <td>78.694230</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2513.040943</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12093</th>\n",
       "      <td>26.981900</td>\n",
       "      <td>78.042265</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2505.040738</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12094</th>\n",
       "      <td>25.228414</td>\n",
       "      <td>78.670817</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2560.914603</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12095</th>\n",
       "      <td>26.209149</td>\n",
       "      <td>78.045677</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2527.698203</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12096</th>\n",
       "      <td>30.700001</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1504.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4095.000000</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12097</th>\n",
       "      <td>30.700001</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1478.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4095.000000</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12098</th>\n",
       "      <td>30.700001</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1494.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4095.000000</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       temperature   humidity     gas  motion     dampness  trash\n",
       "12075    25.352686  81.812249  1303.0      10  2539.400689    3.0\n",
       "12076    25.286756  80.563007  1396.0       3  2569.288370    3.0\n",
       "12077    25.983841  80.523062  1445.0       8  2574.292953    3.0\n",
       "12078    25.813435  81.497120  1348.0       7  2570.832162    3.0\n",
       "12079    26.150245  81.782440  1176.0       0  2554.995460    3.0\n",
       "12080    25.309083  78.560073  1192.0       0  2551.334335    3.0\n",
       "12081    25.911777  79.555061  1134.0       0  2560.659132    3.0\n",
       "12082    26.179877  78.652718  1133.0       0  2570.963033    3.0\n",
       "12083    25.292050  79.030021  1221.0       0  2544.486094    3.0\n",
       "12084    25.944225  79.344535  1122.0       0  2583.068353    3.0\n",
       "12085    25.508473  78.970599  1284.0       0  2536.759795    3.0\n",
       "12086    26.104548  78.876024  1157.0       0  2512.302062    3.0\n",
       "12087    26.137773  79.108537  1140.0       0  2502.450573    3.0\n",
       "12088    26.988470  78.219620  1268.0       0  2539.282232    3.0\n",
       "12089    25.528272  78.287858  1106.0       0  2563.526508    3.0\n",
       "12090    25.813820  78.988355  1236.0       0  2549.314699    3.0\n",
       "12091    26.284555  78.988115  1275.0       0  2567.093076    3.0\n",
       "12092    26.898266  78.694230  1220.0       0  2513.040943    3.0\n",
       "12093    26.981900  78.042265  1220.0       0  2505.040738    3.0\n",
       "12094    25.228414  78.670817  1123.0       0  2560.914603    3.0\n",
       "12095    26.209149  78.045677  1284.0       0  2527.698203    3.0\n",
       "12096    30.700001  60.000000  1504.0      10  4095.000000   15.0\n",
       "12097    30.700001  60.000000  1478.0      10  4095.000000   15.0\n",
       "12098    30.700001  60.000000  1494.0      10  4095.000000   15.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_df = pd.read_csv(path)\n",
    "curr_df = curr_df.iloc[-24:, 2:-1] # take last 24 datapoints and remove ratings, date and time\n",
    "curr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa20d8be-5c3a-4b85-b5cf-31ee6fc450e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:445: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:445: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:445: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:445: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:445: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:445: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:445: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:445: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:445: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# loading telegram bot \n",
    "BOT_TOKEN = '6528183755:AAFdxN_1-wixTemIpCBq8j-ulJHTI_hAgZ0'\n",
    "\n",
    "bot = telebot.TeleBot(BOT_TOKEN)\n",
    "\n",
    "markup = types.InlineKeyboardMarkup(row_width=1)\n",
    "\n",
    "@bot.message_handler(commands=['start'])\n",
    "def pick_role(message): \n",
    "    cleaner = types.InlineKeyboardButton('cleaner', callback_data='cleaner')\n",
    "    owner = types.InlineKeyboardButton('building owner', callback_data='owner')\n",
    "    \n",
    "    markup = types.InlineKeyboardMarkup(row_width=1)\n",
    "    markup.add(cleaner, owner)\n",
    "    bot.send_message(message.chat.id, 'pick a role!', reply_markup=markup)\n",
    "\n",
    "        \n",
    "@bot.callback_query_handler(func=lambda call: call.data == 'cleaner')\n",
    "def cleaner_select(callback): \n",
    "    pred_clean = types.InlineKeyboardButton('predict next cleaning', callback_data='pred_clean')\n",
    "    temp_trend = types.InlineKeyboardButton('check temperature trend', callback_data='temp_trend')\n",
    "    hum_trend = types.InlineKeyboardButton('check humidity trend', callback_data='hum_trend')\n",
    "    gas_trend = types.InlineKeyboardButton('check gas trend', callback_data='gas_trend')\n",
    "    motion_trend = types.InlineKeyboardButton('check motion trend', callback_data='motion_trend')\n",
    "    damp_trend = types.InlineKeyboardButton('check dampness trend', callback_data='damp_trend')\n",
    "    trash_trend = types.InlineKeyboardButton('check trash trend', callback_data='trash_trend')\n",
    "    rating_trend = types.InlineKeyboardButton('check rating trend', callback_data='rating_trend')\n",
    "    \n",
    "    markup = types.InlineKeyboardMarkup(row_width=1)\n",
    "    markup.add(pred_clean, temp_trend, hum_trend, gas_trend, motion_trend, damp_trend, trash_trend, rating_trend)\n",
    "    bot.send_message(callback.message.chat.id, 'what do you wish to check?', reply_markup=markup)\n",
    "\n",
    "@bot.callback_query_handler(func=lambda call: call.data == 'owner')\n",
    "def owner_select(callback): \n",
    "    temp_stats = types.InlineKeyboardButton('check temperature stats', callback_data='temp_stats')\n",
    "    hum_stats = types.InlineKeyboardButton('check humidity stats', callback_data='hum_stats')\n",
    "    gas_stats = types.InlineKeyboardButton('check gas stats', callback_data='gas_stats')\n",
    "    motion_stats = types.InlineKeyboardButton('check motion stats', callback_data='motion_stats')\n",
    "    damp_stats = types.InlineKeyboardButton('check dampness stats', callback_data='damp_stats')\n",
    "    trash_stats = types.InlineKeyboardButton('check trash stats', callback_data='trash_stats')\n",
    "    rating_stats = types.InlineKeyboardButton('check rating stats', callback_data='rating_stats')\n",
    "    \n",
    "    markup = types.InlineKeyboardMarkup(row_width=1)\n",
    "    markup.add(temp_stats, hum_stats, gas_stats, motion_stats, damp_stats, trash_stats, rating_stats)\n",
    "    bot.send_message(callback.message.chat.id, 'what do you wish to check?', reply_markup=markup)\n",
    "    \n",
    "@bot.callback_query_handler(func=lambda call: call.data == 'pred_clean')\n",
    "def pred_clean(callback):\n",
    "    markup = types.InlineKeyboardMarkup(row_width=1)\n",
    "    \n",
    "    curr_df = pd.read_csv(path)\n",
    "    curr_df = curr_df.iloc[-24:, 2:-1] # take last 24 datapoints and remove ratings, date and time\n",
    "    \n",
    "    test_data = curr_df.values.tolist()\n",
    "    test_data = sc.transform(test_data)\n",
    "    test_data = torch.tensor(np.array(test_data)).float()\n",
    "    \n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        while True:\n",
    "            curr = lstm(test_data)\n",
    "            test_data = curr\n",
    "            \n",
    "            outputs = classifier(torch.Tensor(np.array([np.array(curr[-1])])))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            if (np.array(predicted) < 3): # need to clean (if rating 0, 1, 2-> 1, 2, 3)\n",
    "                break \n",
    "                \n",
    "            count += 1\n",
    "    \n",
    "    msg = \"Cleaning is predicted to be required in: \" + str(count*5) + \" minutes.\"\n",
    "    bot.send_message(callback.message.chat.id, msg, reply_markup=markup)\n",
    "    \n",
    "@bot.callback_query_handler(func=lambda call: call.data == 'temp_trend')\n",
    "def temp_trend(callback):\n",
    "    curr_df = pd.read_csv(path)\n",
    "    curr_df = curr_df.iloc[-24:, 2:-1] # take last 24 datapoints and remove ratings, date and time \n",
    "    \n",
    "    arr = curr_df['temperature'].values.tolist()\n",
    "    \n",
    "    test_data = curr_df.values.tolist()\n",
    "    test_data = sc.transform(test_data)\n",
    "    test_data = torch.tensor(np.array(test_data)).float()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(24): \n",
    "            curr = lstm(test_data)\n",
    "            test_data = curr\n",
    "            \n",
    "            curr = sc.inverse_transform(curr)\n",
    "            arr.append(curr[-1, 0]) # make sure temperature is column 0 \n",
    "            \n",
    "    plt.figure()\n",
    "    plt.plot(np.linspace(-120, 120, 48), arr, c=\"r\")\n",
    "    plt.xlabel(\"Time/mins\")\n",
    "    plt.ylabel(\"Temperature/degC\")\n",
    "    plt.axvline(x=0, color='b', linestyle='--', label='now')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"temp_plot.png\")\n",
    "        \n",
    "    # Send the image\n",
    "    with open('temp_plot.png', 'rb') as photo:\n",
    "        bot.send_photo(callback.message.chat.id, photo, caption='Temperature Trend')\n",
    "        \n",
    "@bot.callback_query_handler(func=lambda call: call.data == 'hum_trend')\n",
    "def hum_trend(callback):\n",
    "    curr_df = pd.read_csv(path)\n",
    "    curr_df = curr_df.iloc[-24:, 2:-1] # take last 24 datapoints and remove ratings, date and time\n",
    "    \n",
    "    arr = curr_df['humidity'].values.tolist()\n",
    "    \n",
    "    test_data = curr_df.values.tolist()\n",
    "    test_data = sc.transform(test_data)\n",
    "    test_data = torch.tensor(np.array(test_data)).float()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(24): \n",
    "            curr = lstm(test_data)\n",
    "            test_data = curr\n",
    "            \n",
    "            curr = sc.inverse_transform(curr)\n",
    "            arr.append(curr[-1, 1]) \n",
    "            \n",
    "    plt.figure()\n",
    "    plt.plot(np.linspace(-120, 120, 48), arr, c=\"r\")\n",
    "    plt.xlabel(\"Time/mins\")\n",
    "    plt.ylabel(\"Humidity/%\")\n",
    "    plt.axvline(x=0, color='b', linestyle='--', label='now')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"hum_plot.png\")\n",
    "        \n",
    "    # Send the image\n",
    "    with open('hum_plot.png', 'rb') as photo:\n",
    "        bot.send_photo(callback.message.chat.id, photo, caption='Humidity Trend')\n",
    "        \n",
    "@bot.callback_query_handler(func=lambda call: call.data == 'gas_trend')\n",
    "def gas_trend(callback):\n",
    "    curr_df = pd.read_csv(path)\n",
    "    curr_df = curr_df.iloc[-24:, 2:-1] # take last 24 datapoints and remove ratings, date and time\n",
    "    \n",
    "    arr = curr_df['gas'].values.tolist()\n",
    "    \n",
    "    test_data = curr_df.values.tolist()\n",
    "    test_data = sc.transform(test_data)\n",
    "    test_data = torch.tensor(np.array(test_data)).float()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(24): \n",
    "            curr = lstm(test_data)\n",
    "            test_data = curr\n",
    "            \n",
    "            curr = sc.inverse_transform(curr)\n",
    "            arr.append(curr[-1, 2]) \n",
    "            \n",
    "    plt.figure()\n",
    "    plt.plot(np.linspace(-120, 120, 48), arr, c=\"r\")\n",
    "    plt.xlabel(\"Time/mins\")\n",
    "    plt.ylabel(\"Gas\")\n",
    "    plt.axvline(x=0, color='b', linestyle='--', label='now')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"gas_plot.png\")\n",
    "        \n",
    "    # Send the image\n",
    "    with open('gas_plot.png', 'rb') as photo:\n",
    "        bot.send_photo(callback.message.chat.id, photo, caption='Gas Trend')\n",
    "        \n",
    "@bot.callback_query_handler(func=lambda call: call.data == 'motion_trend')\n",
    "def motion_trend(callback):\n",
    "    curr_df = pd.read_csv(path)\n",
    "    curr_df = curr_df.iloc[-24:, 2:-1] # take last 24 datapoints and remove ratings, date and time \n",
    "    \n",
    "    arr = curr_df['motion'].values.tolist()\n",
    "    \n",
    "    test_data = curr_df.values.tolist()\n",
    "    test_data = sc.transform(test_data)\n",
    "    test_data = torch.tensor(np.array(test_data)).float()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(24): \n",
    "            curr = lstm(test_data)\n",
    "            test_data = curr\n",
    "            \n",
    "            curr = sc.inverse_transform(curr)\n",
    "            arr.append(curr[-1, 3]) \n",
    "            \n",
    "    plt.figure()\n",
    "    plt.plot(np.linspace(-120, 120, 48), arr, c=\"r\")\n",
    "    plt.xlabel(\"Time/mins\")\n",
    "    plt.ylabel(\"Motion\")\n",
    "    plt.axvline(x=0, color='b', linestyle='--', label='now')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"motion_plot.png\")\n",
    "        \n",
    "    # Send the image\n",
    "    with open('motion_plot.png', 'rb') as photo:\n",
    "        bot.send_photo(callback.message.chat.id, photo, caption='Motion Trend')\n",
    "        \n",
    "@bot.callback_query_handler(func=lambda call: call.data == 'damp_trend')\n",
    "def damp_trend(callback):\n",
    "    curr_df = pd.read_csv(path)\n",
    "    curr_df = curr_df.iloc[-24:, 2:-1] # take last 24 datapoints and remove ratings, date and time\n",
    "    \n",
    "    arr = curr_df['dampness'].values.tolist()\n",
    "    \n",
    "    test_data = curr_df.values.tolist()\n",
    "    test_data = sc.transform(test_data)\n",
    "    test_data = torch.tensor(np.array(test_data)).float()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(24): \n",
    "            curr = lstm(test_data)\n",
    "            test_data = curr\n",
    "            \n",
    "            curr = sc.inverse_transform(curr)\n",
    "            arr.append(curr[-1, 4]) \n",
    "            \n",
    "    plt.figure()\n",
    "    plt.plot(np.linspace(-120, 120, 48), arr, c=\"r\")\n",
    "    plt.xlabel(\"Time/mins\")\n",
    "    plt.ylabel(\"Dampness\")\n",
    "    plt.axvline(x=0, color='b', linestyle='--', label='now')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"damp_plot.png\")\n",
    "        \n",
    "    # Send the image\n",
    "    with open('damp_plot.png', 'rb') as photo:\n",
    "        bot.send_photo(callback.message.chat.id, photo, caption='Dampness Trend')\n",
    "        \n",
    "@bot.callback_query_handler(func=lambda call: call.data == 'trash_trend')\n",
    "def trash_trend(callback):\n",
    "    curr_df = pd.read_csv(path)\n",
    "    curr_df = curr_df.iloc[-24:, 2:-1] # take last 24 datapoints and remove ratings, date and time \n",
    "    \n",
    "    arr = curr_df['trash'].values.tolist()\n",
    "    \n",
    "    test_data = curr_df.values.tolist()\n",
    "    test_data = sc.transform(test_data)\n",
    "    test_data = torch.tensor(np.array(test_data)).float()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(24): \n",
    "            curr = lstm(test_data)\n",
    "            test_data = curr\n",
    "            \n",
    "            curr = sc.inverse_transform(curr)\n",
    "            arr.append(curr[-1, 5]) \n",
    "            \n",
    "    plt.figure()\n",
    "    plt.plot(np.linspace(-120, 120, 48), arr, c=\"r\")\n",
    "    plt.xlabel(\"Time/mins\")\n",
    "    plt.ylabel(\"Trash\")\n",
    "    plt.axvline(x=0, color='b', linestyle='--', label='now')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"trash_plot.png\")\n",
    "        \n",
    "    # Send the image\n",
    "    with open('trash_plot.png', 'rb') as photo:\n",
    "        bot.send_photo(callback.message.chat.id, photo, caption='Trash Trend')\n",
    "        \n",
    "@bot.callback_query_handler(func=lambda call: call.data == 'rating_trend')\n",
    "def rating_trend(callback):\n",
    "    curr_df = pd.read_csv(path)\n",
    "    \n",
    "    arr = curr_df.iloc[-24:, -1].values.tolist()\n",
    "    curr_df = curr_df.iloc[-24:, 2:-1] # take last 24 datapoints and remove ratings, date and time\n",
    "    \n",
    "    test_data = curr_df.values.tolist()\n",
    "    test_data = sc.transform(test_data)\n",
    "    test_data = torch.tensor(np.array(test_data)).float()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(24): \n",
    "            curr = lstm(test_data)\n",
    "            test_data = curr\n",
    "            \n",
    "            outputs = classifier(torch.Tensor(np.array([np.array(curr[-1])])))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            arr.append(int(np.array(predicted)[0]) + 1)\n",
    "            \n",
    "    plt.figure()\n",
    "    plt.plot(np.linspace(-120, 120, 48), arr, c=\"r\")\n",
    "    plt.xlabel(\"Time/mins\")\n",
    "    plt.ylabel(\"Ratings\")\n",
    "    plt.axvline(x=0, color='b', linestyle='--', label='now')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"ratings_plot.png\")\n",
    "        \n",
    "    # Send the image\n",
    "    with open('ratings_plot.png', 'rb') as photo:\n",
    "        bot.send_photo(callback.message.chat.id, photo, caption='Ratings Trend')\n",
    "        \n",
    "@bot.callback_query_handler(func=lambda call: call.data == 'temp_stats')\n",
    "def temp_stats(callback):\n",
    "    # collecting november data \n",
    "    start_dt = datetime.datetime(2023, 11, 1)\n",
    "    end_dt = datetime.datetime(2023, 11, 30)\n",
    "\n",
    "    # data preparation \n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # filter to only contain november data \n",
    "    df['dt_day'] = df['day'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d'))\n",
    "    df = df[df['dt_day'] >= start_dt]\n",
    "    df = df[df['dt_day'] <= end_dt]\n",
    "    df['fill_time'] = df['time'].apply(lambda x: x.zfill(5))\n",
    "    \n",
    "    # plot average daily temp\n",
    "    dt = start_dt \n",
    "    dt_arr = []\n",
    "    temp_arr = []\n",
    "    while (dt <= end_dt):\n",
    "        dt_arr.append(dt.strftime(\"%Y-%m-%d\"))\n",
    "        temp_arr.append(list(df[df['dt_day'] == dt]['temperature'].values))\n",
    "        dt += datetime.timedelta(days=1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.boxplot(temp_arr, labels=dt_arr)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel('date')\n",
    "    plt.ylabel('temperature/degC')\n",
    "    plt.savefig(\"plot.png\", bbox_inches='tight')\n",
    "        \n",
    "    # Send the image\n",
    "    with open('plot.png', 'rb') as photo:\n",
    "        bot.send_photo(callback.message.chat.id, photo)\n",
    "\n",
    "    # plot average temp throughout the day \n",
    "    time_arr = []\n",
    "    temp_arr = []\n",
    "    curr_time = datetime.datetime(year=2023, month=1, day=1, hour=0, minute=0, second=0)\n",
    "    end_time = datetime.datetime(year=2023, month=1, day=1, hour=23, minute=55, second=0)\n",
    "    while (curr_time <= end_time): \n",
    "        time_arr.append(curr_time.strftime(\"%H:%M\"))\n",
    "        temp_arr.append(np.mean(df[df['fill_time'] == curr_time.strftime(\"%H:%M\")]['temperature'].values))\n",
    "        curr_time += datetime.timedelta(minutes=5)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(time_arr, temp_arr)\n",
    "    x_values = time_arr[::12] # show every 1 hour label \n",
    "    plt.xticks(x_values, rotation=45)\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('average temperature/degC')\n",
    "    plt.savefig(\"plot.png\")\n",
    "        \n",
    "    # Send the image\n",
    "    with open('plot.png', 'rb') as photo:\n",
    "        bot.send_photo(callback.message.chat.id, photo)\n",
    "\n",
    "    # output overall averages \n",
    "    msg = 'Overall Average Temperature: ' + str(np.mean(df['temperature'].values))\n",
    "    bot.send_message(callback.message.chat.id, msg, reply_markup=markup)\n",
    "\n",
    "@bot.callback_query_handler(func=lambda call: call.data == 'hum_stats')\n",
    "def hum_stats(callback):\n",
    "    # collecting november data \n",
    "    start_dt = datetime.datetime(2023, 11, 1)\n",
    "    end_dt = datetime.datetime(2023, 11, 30)\n",
    "\n",
    "    # data preparation \n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # filter to only contain november data \n",
    "    df['dt_day'] = df['day'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d'))\n",
    "    df = df[df['dt_day'] >= start_dt]\n",
    "    df = df[df['dt_day'] <= end_dt]\n",
    "    df['fill_time'] = df['time'].apply(lambda x: x.zfill(5))\n",
    "    \n",
    "    # plot average daily humidity\n",
    "    dt = start_dt \n",
    "    dt_arr = []\n",
    "    hum_arr = []\n",
    "    while (dt <= end_dt):\n",
    "        dt_arr.append(dt.strftime(\"%Y-%m-%d\"))\n",
    "        hum_arr.append(list(df[df['dt_day'] == dt]['humidity'].values))\n",
    "        dt += datetime.timedelta(days=1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.boxplot(hum_arr, labels=dt_arr)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel('date')\n",
    "    plt.ylabel('humidity/%')\n",
    "    plt.savefig(\"plot.png\", bbox_inches='tight')\n",
    "        \n",
    "    # Send the image\n",
    "    with open('plot.png', 'rb') as photo:\n",
    "        bot.send_photo(callback.message.chat.id, photo)\n",
    "\n",
    "    # plot average humidity throughout the day \n",
    "    time_arr = []\n",
    "    hum_arr = []\n",
    "    curr_time = datetime.datetime(year=2023, month=1, day=1, hour=0, minute=0, second=0)\n",
    "    end_time = datetime.datetime(year=2023, month=1, day=1, hour=23, minute=55, second=0)\n",
    "    while (curr_time <= end_time): \n",
    "        time_arr.append(curr_time.strftime(\"%H:%M\"))\n",
    "        hum_arr.append(np.mean(df[df['fill_time'] == curr_time.strftime(\"%H:%M\")]['humidity'].values))\n",
    "        curr_time += datetime.timedelta(minutes=5)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(time_arr, hum_arr)\n",
    "    x_values = time_arr[::12] # show every 1 hour label \n",
    "    plt.xticks(x_values, rotation=45)\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('average humidity/%')\n",
    "    plt.savefig(\"plot.png\", bbox_inches='tight')\n",
    "        \n",
    "    # Send the image\n",
    "    with open('plot.png', 'rb') as photo:\n",
    "        bot.send_photo(callback.message.chat.id, photo)\n",
    "\n",
    "    # output overall average humidity \n",
    "    msg = 'Overall Average Humidity: ' + str(np.mean(df['humidity'].values))\n",
    "    bot.send_message(callback.message.chat.id, msg, reply_markup=markup)\n",
    "    \n",
    "@bot.callback_query_handler(func=lambda call: call.data == 'gas_stats')\n",
    "def gas_stats(callback):\n",
    "    # collecting november data \n",
    "    start_dt = datetime.datetime(2023, 11, 1)\n",
    "    end_dt = datetime.datetime(2023, 11, 30)\n",
    "\n",
    "    # data preparation \n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # filter to only contain november data \n",
    "    df['dt_day'] = df['day'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d'))\n",
    "    df = df[df['dt_day'] >= start_dt]\n",
    "    df = df[df['dt_day'] <= end_dt]\n",
    "    df['fill_time'] = df['time'].apply(lambda x: x.zfill(5))\n",
    "    \n",
    "    # plot average daily gas\n",
    "    dt = start_dt \n",
    "    dt_arr = []\n",
    "    gas_arr = []\n",
    "    while (dt <= end_dt):\n",
    "        dt_arr.append(dt.strftime(\"%Y-%m-%d\"))\n",
    "        gas_arr.append(list(df[df['dt_day'] == dt]['gas'].values))\n",
    "        dt += datetime.timedelta(days=1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.boxplot(gas_arr, labels=dt_arr)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel('date')\n",
    "    plt.ylabel('gas')\n",
    "    plt.savefig(\"plot.png\", bbox_inches='tight')\n",
    "        \n",
    "    # Send the image\n",
    "    with open('plot.png', 'rb') as photo:\n",
    "        bot.send_photo(callback.message.chat.id, photo)\n",
    "\n",
    "    # plot average dampness throughout the day \n",
    "    time_arr = []\n",
    "    gas_arr = []\n",
    "    curr_time = datetime.datetime(year=2023, month=1, day=1, hour=0, minute=0, second=0)\n",
    "    end_time = datetime.datetime(year=2023, month=1, day=1, hour=23, minute=55, second=0)\n",
    "    while (curr_time <= end_time): \n",
    "        time_arr.append(curr_time.strftime(\"%H:%M\"))\n",
    "        gas_arr.append(np.mean(df[df['fill_time'] == curr_time.strftime(\"%H:%M\")]['gas'].values))\n",
    "        curr_time += datetime.timedelta(minutes=5)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(time_arr, gas_arr)\n",
    "    x_values = time_arr[::12] # show every 1 hour label \n",
    "    plt.xticks(x_values, rotation=45)\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('average gas')\n",
    "    plt.savefig(\"plot.png\", bbox_inches='tight')\n",
    "        \n",
    "    # Send the image\n",
    "    with open('plot.png', 'rb') as photo:\n",
    "        bot.send_photo(callback.message.chat.id, photo)\n",
    "\n",
    "    # output overall average gas \n",
    "    msg = 'Overall Average Gas: ' + str(np.mean(df['gas'].values))\n",
    "    bot.send_message(callback.message.chat.id, msg, reply_markup=markup)\n",
    "    \n",
    "@bot.callback_query_handler(func=lambda call: call.data == 'motion_stats')\n",
    "def motion_stats(callback):\n",
    "    # collecting november data \n",
    "    start_dt = datetime.datetime(2023, 11, 1)\n",
    "    end_dt = datetime.datetime(2023, 11, 30)\n",
    "\n",
    "    # data preparation \n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # filter to only contain november data \n",
    "    df['dt_day'] = df['day'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d'))\n",
    "    df = df[df['dt_day'] >= start_dt]\n",
    "    df = df[df['dt_day'] <= end_dt]\n",
    "    df['fill_time'] = df['time'].apply(lambda x: x.zfill(5))\n",
    "    \n",
    "    # plot average daily motion \n",
    "    dt = start_dt \n",
    "    dt_arr = []\n",
    "    motion_arr = []\n",
    "    while (dt <= end_dt):\n",
    "        dt_arr.append(dt.strftime(\"%Y-%m-%d\"))\n",
    "        motion_arr.append(list(df[df['dt_day'] == dt]['motion'].values))\n",
    "        dt += datetime.timedelta(days=1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.boxplot(motion_arr, labels=dt_arr)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel('date')\n",
    "    plt.ylabel('average motion per 5 min interval')\n",
    "    plt.savefig(\"plot.png\", bbox_inches='tight')\n",
    "        \n",
    "    # Send the image\n",
    "    with open('plot.png', 'rb') as photo:\n",
    "        bot.send_photo(callback.message.chat.id, photo)\n",
    "\n",
    "    # plot average motion throughout the day \n",
    "    time_arr = []\n",
    "    motion_arr = []\n",
    "    curr_time = datetime.datetime(year=2023, month=1, day=1, hour=0, minute=0, second=0)\n",
    "    end_time = datetime.datetime(year=2023, month=1, day=1, hour=23, minute=55, second=0)\n",
    "    while (curr_time <= end_time): \n",
    "        time_arr.append(curr_time.strftime(\"%H:%M\"))\n",
    "        motion_arr.append(np.mean(df[df['fill_time'] == curr_time.strftime(\"%H:%M\")]['motion'].values))\n",
    "        curr_time += datetime.timedelta(minutes=5)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(time_arr, motion_arr)\n",
    "    x_values = time_arr[::12] # show every 1 hour label \n",
    "    plt.xticks(x_values, rotation=45)\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('average motion per 5 min interval')\n",
    "    plt.savefig(\"plot.png\", bbox_inches='tight')\n",
    "        \n",
    "    # Send the image\n",
    "    with open('plot.png', 'rb') as photo:\n",
    "        bot.send_photo(callback.message.chat.id, photo)\n",
    "\n",
    "    # output overall averages \n",
    "    msg = 'Overall Average Motion Per 5 min Interval: ' + str(np.mean(df['motion'].values))\n",
    "    msg += '\\nOverall Maximum Motion Per 5 min Interval: ' + str(np.max(df['motion'].values))\n",
    "    bot.send_message(callback.message.chat.id, msg, reply_markup=markup)\n",
    "    \n",
    "@bot.callback_query_handler(func=lambda call: call.data == 'damp_stats')\n",
    "def damp_stats(callback):\n",
    "    # collecting november data \n",
    "    start_dt = datetime.datetime(2023, 11, 1)\n",
    "    end_dt = datetime.datetime(2023, 11, 30)\n",
    "\n",
    "    # data preparation \n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # filter to only contain november data \n",
    "    df['dt_day'] = df['day'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d'))\n",
    "    df = df[df['dt_day'] >= start_dt]\n",
    "    df = df[df['dt_day'] <= end_dt]\n",
    "    df['fill_time'] = df['time'].apply(lambda x: x.zfill(5))\n",
    "\n",
    "    # plot average daily dampness\n",
    "    dt = start_dt \n",
    "    dt_arr = []\n",
    "    damp_arr = []\n",
    "    while (dt <= end_dt):\n",
    "        dt_arr.append(dt.strftime(\"%Y-%m-%d\"))\n",
    "        damp_arr.append(list(df[df['dt_day'] == dt]['dampness'].values))\n",
    "        dt += datetime.timedelta(days=1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.boxplot(damp_arr, labels=dt_arr)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel('date')\n",
    "    plt.ylabel('dampness')\n",
    "    plt.savefig(\"plot.png\", bbox_inches='tight')\n",
    "        \n",
    "    # Send the image\n",
    "    with open('plot.png', 'rb') as photo:\n",
    "        bot.send_photo(callback.message.chat.id, photo)\n",
    "\n",
    "    # plot average dampness throughout the day \n",
    "    time_arr = []\n",
    "    damp_arr = []\n",
    "    curr_time = datetime.datetime(year=2023, month=1, day=1, hour=0, minute=0, second=0)\n",
    "    end_time = datetime.datetime(year=2023, month=1, day=1, hour=23, minute=55, second=0)\n",
    "    while (curr_time <= end_time): \n",
    "        time_arr.append(curr_time.strftime(\"%H:%M\"))\n",
    "        damp_arr.append(np.mean(df[df['fill_time'] == curr_time.strftime(\"%H:%M\")]['dampness'].values))\n",
    "        curr_time += datetime.timedelta(minutes=5)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(time_arr, damp_arr)\n",
    "    x_values = time_arr[::12] # show every 1 hour label \n",
    "    plt.xticks(x_values, rotation=45)\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('average dampness')\n",
    "    plt.savefig(\"plot.png\", bbox_inches='tight')\n",
    "        \n",
    "    # Send the image\n",
    "    with open('plot.png', 'rb') as photo:\n",
    "        bot.send_photo(callback.message.chat.id, photo)\n",
    "\n",
    "    # output overall average dampness \n",
    "    msg = 'Overall Average Dampness: ' + str(np.mean(df['dampness'].values))\n",
    "    bot.send_message(callback.message.chat.id, msg, reply_markup=markup)\n",
    "\n",
    "@bot.callback_query_handler(func=lambda call: call.data == 'trash_stats')\n",
    "def trash_stats(callback):\n",
    "    # collecting november data \n",
    "    start_dt = datetime.datetime(2023, 11, 1)\n",
    "    end_dt = datetime.datetime(2023, 11, 30)\n",
    "    \n",
    "    # data preparation \n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    # filter to only contain november data \n",
    "    df['dt_day'] = df['day'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d'))\n",
    "    df = df[df['dt_day'] >= start_dt]\n",
    "    df = df[df['dt_day'] <= end_dt]\n",
    "    df['fill_time'] = df['time'].apply(lambda x: x.zfill(5))  \n",
    "    \n",
    "    # plot average daily trend of trashbin \n",
    "    time_arr = []\n",
    "    trash_arr = []\n",
    "    curr_time = datetime.datetime(year=2023, month=1, day=1, hour=0, minute=0, second=0)\n",
    "    end_time = datetime.datetime(year=2023, month=1, day=1, hour=23, minute=55, second=0)\n",
    "    while (curr_time <= end_time): \n",
    "        time_arr.append(curr_time.strftime(\"%H:%M\"))\n",
    "        trash_arr.append(np.mean(df[df['fill_time'] == curr_time.strftime(\"%H:%M\")]['trash'].values)- 3)\n",
    "        curr_time += datetime.timedelta(minutes=5)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(time_arr, trash_arr)\n",
    "    x_values = time_arr[::12] # show every 1 hour label \n",
    "    plt.xticks(x_values, rotation=45)\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('average trash capacity left/cm')\n",
    "    plt.savefig(\"plot.png\", bbox_inches='tight')\n",
    "        \n",
    "    # Send the image\n",
    "    with open('plot.png', 'rb') as photo:\n",
    "        bot.send_photo(callback.message.chat.id, photo)\n",
    "\n",
    "    # plot time when trash bin fills up \n",
    "    dt = start_dt \n",
    "    dt_arr = []\n",
    "    trash_arr = []\n",
    "    temp_dict = {}\n",
    "    while (dt <= end_dt):\n",
    "        dt_arr.append(dt.strftime(\"%Y-%m-%d\"))\n",
    "        temp_df = df[df['dt_day'] == dt]\n",
    "        trash_arr.append(temp_df[temp_df['trash'] == 3].iloc[0]['fill_time'])\n",
    "        dt += datetime.timedelta(days=1)\n",
    "\n",
    "    temp_dict['date'] = dt_arr \n",
    "    temp_dict['time where trash bin is first filled'] = trash_arr\n",
    "    temp_df = pd.DataFrame(temp_dict)\n",
    "    \n",
    "    msg = str(temp_df)\n",
    "    bot.send_message(callback.message.chat.id, msg, reply_markup=markup)\n",
    "    \n",
    "@bot.callback_query_handler(func=lambda call: call.data == 'rating_stats')\n",
    "def rating_stats(callback):\n",
    "    # collecting november data \n",
    "    start_dt = datetime.datetime(2023, 11, 1)\n",
    "    end_dt = datetime.datetime(2023, 11, 30)\n",
    "\n",
    "    # data preparation \n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # filter to only contain november data \n",
    "    df['dt_day'] = df['day'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d'))\n",
    "    df = df[df['dt_day'] >= start_dt]\n",
    "    df = df[df['dt_day'] <= end_dt]\n",
    "    df['fill_time'] = df['time'].apply(lambda x: x.zfill(5))\n",
    "    \n",
    "    # plot average daily ratings \n",
    "    dt = start_dt \n",
    "    dt_arr = []\n",
    "    ratings_arr = []\n",
    "    while (dt <= end_dt):\n",
    "        dt_arr.append(dt.strftime(\"%Y-%m-%d\"))\n",
    "        ratings_arr.append(np.mean(df[df['dt_day'] == dt]['rating'].values))\n",
    "        dt += datetime.timedelta(days=1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(dt_arr, ratings_arr)\n",
    "    plt.xticks(dt_arr, dt_arr, rotation=45)\n",
    "    plt.xlabel('date')\n",
    "    plt.ylabel('average rating')\n",
    "    plt.savefig(\"plot.png\", bbox_inches='tight')\n",
    "        \n",
    "    # Send the image\n",
    "    with open('plot.png', 'rb') as photo:\n",
    "        bot.send_photo(callback.message.chat.id, photo)\n",
    "\n",
    "    # plot average ratings throughout the day \n",
    "    time_arr = []\n",
    "    ratings_arr = []\n",
    "    curr_time = datetime.datetime(year=2023, month=1, day=1, hour=0, minute=0, second=0)\n",
    "    end_time = datetime.datetime(year=2023, month=1, day=1, hour=23, minute=55, second=0)\n",
    "    while (curr_time <= end_time): \n",
    "        time_arr.append(curr_time.strftime(\"%H:%M\"))\n",
    "        ratings_arr.append(np.mean(df[df['fill_time'] == curr_time.strftime(\"%H:%M\")]['rating'].values))\n",
    "        curr_time += datetime.timedelta(minutes=5)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(time_arr, ratings_arr)\n",
    "    x_values = time_arr[::12] # show every 1 hour label \n",
    "    plt.xticks(x_values, rotation=45)\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('average rating')\n",
    "    plt.savefig(\"plot.png\", bbox_inches='tight')\n",
    "        \n",
    "    # Send the image\n",
    "    with open('plot.png', 'rb') as photo:\n",
    "        bot.send_photo(callback.message.chat.id, photo)\n",
    "\n",
    "    # plot histogram of aggregated ratings \n",
    "    plt.figure()\n",
    "    bin_edges = [1, 2, 3, 4, 5]  \n",
    "    plt.hist(df['rating'].values, bins=bin_edges, color='c', alpha=0.7)\n",
    "    plt.xlabel('ratings')\n",
    "    plt.ylabel('count')\n",
    "    plt.savefig(\"plot.png\", bbox_inches='tight')\n",
    "        \n",
    "    # Send the image\n",
    "    with open('plot.png', 'rb') as photo:\n",
    "        bot.send_photo(callback.message.chat.id, photo)\n",
    "\n",
    "    # output overall average rating \n",
    "    msg = 'Overall Average Rating for Month: ' + str(np.mean(df['rating'].values))\n",
    "    bot.send_message(callback.message.chat.id, msg, reply_markup=markup)\n",
    "    \n",
    "bot.infinity_polling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08e92b93-1e70-4557-ac26-534dfd4ff2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889c4d31-8649-40ee-bcf5-81665850c9e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-1:492261229750:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
